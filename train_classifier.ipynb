{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e2c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0aa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/content/drive/MyDrive/Colab Notebooks/ecsc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10a11fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torchvision.transforms import ToPILImage\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "from data.datasets import get_loader\n",
    "from make.build_encoder import build_encoder\n",
    "from net.cloud.classifier import AttentionPoolingClassifier\n",
    "\n",
    "TARGET = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416aa607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedState:\n",
    "    def __init__(self):\n",
    "        self.H = 0\n",
    "        self.W = 0\n",
    "        self.downsample = 4\n",
    "\n",
    "state = SharedState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfae09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# %% ===============================================\n",
    "# Initialize dataloaders\n",
    "# Classification loader for class folder structure - returns (image, label) tuples\n",
    "base_dir =  \"drive/MyDrive/Colab Notebooks/ecsc\"\n",
    "train_path = [f\"{base_dir}/GenSC-Testbed/GT_Images_Classification/Train\"]  # Note: needs to be a list\n",
    "test_path = [f\"{base_dir}/GenSC-Testbed/GT_Images_Classification/Test\"]    # Note: needs to be a list\n",
    "\n",
    "train_loader, test_loader = get_loader(\n",
    "    train_dirs=train_path,\n",
    "    test_dirs=test_path,\n",
    "    batch_size=32,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "print(f\"Train loader: {len(train_loader)} batches\")\n",
    "print(f\"Test loader: {len(test_loader)} batches\")\n",
    "\n",
    "# Get class mappings from the dataset\n",
    "idx_to_class = test_loader.dataset.idx_to_class\n",
    "class_to_idx = test_loader.dataset.class_to_idx\n",
    "print(f\"Classes found: {list(class_to_idx.keys())}\")\n",
    "print(f\"Number of classes: {test_loader.dataset.num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81886dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build models\n",
    "encoder = build_encoder(encoder_name='swin', device=device).to(device)\n",
    "\n",
    "# (Option) freeze the encoder for a quick baseline:\n",
    "for p in encoder.parameters():\n",
    "    p.requires_grad = False        # comment‑out to fine‑tune\n",
    "\n",
    "encoder.eval()                    # required even if frozen (BatchNorm, Dropout)\n",
    "\n",
    "# Peek at one batch to discover feature dimension C\n",
    "x0, _ = next(iter(train_loader))          # (1,3,H,W)\n",
    "H0, W0 = x0.shape[2:]\n",
    "encoder.update_resolution(H0, W0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    C = encoder(x0.to(device)).shape[-1]  # (B, N, C) → C\n",
    "\n",
    "num_classes = len(idx_to_class)\n",
    "# clf = GenericClassifier(in_features=C, num_classes=num_classes, hidden=256, agg=\"mean\").to(device)\n",
    "clf = AttentionPoolingClassifier(in_features=C, num_classes=num_classes, hidden=256, dropout=0.3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_groups = [\n",
    "    # {\"params\": [p for p in encoder.parameters() if p.requires_grad], \"lr\": 1e-5},\n",
    "    {\"params\": clf.parameters(), \"lr\": 1e-3},\n",
    "]\n",
    "optimizer = torch.optim.Adam(optim_groups, weight_decay=1e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b0e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train loop\n",
    "EPOCHS = 20\n",
    "for epoch in trange(1, EPOCHS + 1, desc=\"Epochs\"):\n",
    "    encoder.train(); clf.train()\n",
    "    running_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    train_bar = tqdm(train_loader, leave=False, desc=f\"Train {epoch:02d}\", unit=\"batch\")\n",
    "    for imgs, labels in train_bar: # type: ignore\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "\n",
    "        # -- keep your dynamic‑resolution logic ----------------------------\n",
    "        # _, _, H, W = imgs.shape\n",
    "        # if (H, W) != (state.H, state.W):\n",
    "        #     encoder.update_resolution(TARGET, TARGET)\n",
    "        #     state.H, state.W = TARGET, TARGET\n",
    "        # ------------------------------------------------------------------\n",
    "\n",
    "        feats = encoder(imgs)              # (B, N, C)\n",
    "        # print(f\"Features shape: {feats.shape}\")\n",
    "        # print(f\"Features mean: {feats.mean():.4f}, std: {feats.std():.4f}\")\n",
    "        # print(f\"Features min: {feats.min():.4f}, max: {feats.max():.4f}\")\n",
    "\n",
    "        logits = clf(feats)                # (B, num_classes)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = logits.max(1)\n",
    "        total   += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "\n",
    "        train_bar.set_postfix(\n",
    "            loss = f\"{running_loss / total:.4f}\",\n",
    "            acc  = f\"{100 * correct / total:.2f}%\"\n",
    "        )\n",
    "\n",
    "    encoder.eval();  clf.eval()\n",
    "    v_loss, v_correct, v_total = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_bar = tqdm(test_loader, leave=False, desc=f\"Val   {epoch:02d}\", unit=\"batch\")\n",
    "        for imgs, labels in val_bar:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            feats  = encoder(imgs)\n",
    "            logits = clf(feats)\n",
    "            loss   = criterion(logits, labels)\n",
    "\n",
    "            v_loss += loss.item()\n",
    "            _, preds = logits.max(1)\n",
    "            v_total   += labels.size(0)\n",
    "            v_correct += (preds == labels).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    val_acc   = 100 * v_correct / v_total\n",
    "    val_loss  = v_loss / len(test_loader)\n",
    "\n",
    "    # print a one‑liner summary that stays after the bars disappear\n",
    "    print(f\"[{epoch:02d}/{EPOCHS}] \"\n",
    "          f\"train loss {running_loss/len(train_loader):.4f} \"\n",
    "          f\"train acc {train_acc:.2f}% | \"\n",
    "          f\"val loss {val_loss:.4f} val acc {val_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
